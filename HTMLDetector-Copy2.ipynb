{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from scipy.ndimage import morphology, label\n",
    "from keras import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "import os\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "import sys\n",
    "import numpy\n",
    "from PIL import Image, ImageOps, ImageDraw\n",
    "from scipy.ndimage import morphology, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'IMG-3077.jpg' #can modify\n",
    "img1234 = cv2.imread(path)\n",
    "cv2_im = cv2.cvtColor(img1234,cv2.COLOR_BGR2RGB)\n",
    "pil_im = Image.fromarray(cv2_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected components is: 12505\n",
      "finished running boxes!\n",
      "[[[(975, 2940), (1007, 2940), (1007, 2954), (975, 2954)], (991.6425531914894, 2947.391489361702)]]\n",
      "[[[(70, 303), (3503, 303), (3503, 1640), (70, 1640)], (1760.3305423973757, 1147.422299195981)], [[(2569, 333), (2694, 333), (2694, 342), (2569, 342)], (2632.2286282306163, 337.7097415506958)], [[(109, 343), (3456, 343), (3456, 1612), (109, 1612)], (1688.766444032591, 971.4900688883449)], [[(384, 547), (1304, 547), (1304, 1424), (384, 1424)], (872.6809711540533, 940.0813460005601)], [[(2298, 558), (3142, 558), (3142, 1535), (2298, 1535)], (2689.6226055872867, 1016.3489917239772)], [[(656, 561), (1177, 561), (1177, 631), (656, 631)], (916.9293954776189, 600.9935394554684)], [[(2518, 584), (3071, 584), (3071, 608), (2518, 608)], (2770.1892690130444, 595.9778488801378)], [[(2369, 586), (2486, 586), (2486, 592), (2369, 592)], (2426.2525951557095, 589.3910034602076)], [[(127, 747), (141, 747), (141, 800), (127, 800)], (132.38524590163934, 772.2418032786885)], [[(609, 811), (1081, 811), (1081, 1238), (609, 1238)], (879.1253926840956, 1024.3352856610404)], [[(167, 1002), (194, 1002), (194, 1182), (167, 1182)], (182.17986577181208, 1094.2026845637583)], [[(695, 1338), (1193, 1338), (1193, 1390), (695, 1390)], (942.0599793174767, 1360.1354705274043)], [[(682, 1347), (1100, 1347), (1100, 1393), (682, 1393)], (904.6774758983348, 1364.5525854513585)], [[(991, 2916), (1047, 2916), (1047, 2952), (991, 2952)], (1021.2904884318766, 2932.926735218509)], [[(1024, 2955), (1059, 2955), (1059, 2999), (1024, 2999)], (1044.098615916955, 2976.515570934256)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def boxes(orig):\n",
    "    img = ImageOps.grayscale(orig)\n",
    "    im = numpy.array(img)\n",
    "\n",
    "    # Inner morphological gradient.\n",
    "    im = morphology.grey_dilation(im, (3, 3)) - im\n",
    "\n",
    "    # Binarize.\n",
    "    mean, std = im.mean(), im.std()\n",
    "    t = mean + std\n",
    "    im[im < t] = 0\n",
    "    im[im >= t] = 1\n",
    "\n",
    "    # Connected components.\n",
    "    lbl, numcc = label(im)\n",
    "    # Size threshold.\n",
    "    min_size = 200 # pixels\n",
    "    box = []\n",
    "    print(\"Number of connected components is: \" + str(numcc))\n",
    "    for i in range(1, numcc + 1):\n",
    "        py, px = numpy.nonzero(lbl == i)\n",
    "        if len(py) < min_size:\n",
    "            im[lbl == i] = 0\n",
    "            continue\n",
    "\n",
    "        xmin, xmax, ymin, ymax = px.min(), px.max(), py.min(), py.max()\n",
    "        # Four corners and centroid.\n",
    "        box.append([\n",
    "            [(xmin, ymin), (xmax, ymin), (xmax, ymax), (xmin, ymax)],\n",
    "            (numpy.mean(px), numpy.mean(py))])\n",
    "\n",
    "    print(\"finished running boxes!\")\n",
    "    return im.astype(numpy.uint8) * 255, box\n",
    "\n",
    "orig = pil_im\n",
    "im, box = boxes(orig)\n",
    "\n",
    "\n",
    "# Boxes found.\n",
    "def dist(t1, t2):\n",
    "    return np.sqrt((t1[0] - t2[0])**2 + (t1[1] - t2[1])**2)\n",
    "# Draw perfect rectangles and the component centroid.\n",
    "img = Image.fromarray(im)\n",
    "visual = img.convert('RGB')\n",
    "draw = ImageDraw.Draw(visual)\n",
    "box1 = []\n",
    "counter = 1\n",
    "for b,centroid in box:\n",
    "    for b1, centroid1 in box[counter:]:\n",
    "        if dist(b[0], b1[0]) < 50 and (abs((b[1][0] - b[0][0]) - (b1[1][0] - b1[0][0])) < 50) and (abs((b[2][1] - b[0][1]) - (b1[2][1] - b1[0][1])) < 50):\n",
    "            if (b[1][0] - b[0][0]) < (b1[1][0] - b1[0][0]):\n",
    "                smaller = b\n",
    "                smallercent = centroid\n",
    "            else:\n",
    "                smaller = b1\n",
    "                smallercent = centroid1\n",
    "            box1.append([smaller, smallercent])\n",
    "    counter+=1\n",
    "print(box1)\n",
    "for x in box1:\n",
    "    try:\n",
    "        box.remove(x)\n",
    "    except:\n",
    "        continue\n",
    "print(box)\n",
    "for b, centroid in box:\n",
    "    draw.line(b + [b[0]], fill='yellow')\n",
    "    cx, cy = centroid\n",
    "    draw.ellipse((cx - 2, cy - 2, cx + 2, cy + 2), fill='red')\n",
    "#visual.save(sys.argv[3])\n",
    "opencvImage = cv2.cvtColor(numpy.array(visual), cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('testBoxes.png', opencvImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box():\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "        self.children = []\n",
    "box.sort(reverse=True, key= lambda x: abs(x[0][0][0] - x[0][1][0]) * abs(x[0][0][1] - x[0][2][1]))\n",
    "\n",
    "boxes = Box(img1234[box[0][0][0][1]: box[0][0][2][1], box[0][0][0][0]:box[0][0][1][0]])\n",
    "counter1 = 1\n",
    "for b,centroid in box[1:]:\n",
    "    boxes.children.append(Box(img1234[b[0][1]: b[2][1], b[0][0]:b[1][0]]))\n",
    "#cv2.imwrite('testBoxLarge.png', boxes.img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "loaded_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "def box_converter(box):\n",
    "    if box == None:\n",
    "        return\n",
    "    if len(box.children) == 0:\n",
    "        box.img = cv2.resize(box.img, (64, 64)) \n",
    "        test_image = image.img_to_array(box.img)\n",
    "        test_image = np.expand_dims(test_image, axis = 0)\n",
    "        result = loaded_model.predict(test_image)\n",
    "        #training_set.class_indices\n",
    "        if result[0][0] == 1:\n",
    "            prediction = '<div/>'\n",
    "        else:\n",
    "            prediction = '<checkbox/>'\n",
    "        return prediction\n",
    "    elif len(box.children) > 0:\n",
    "        header = '<div/>\\n\\t' \n",
    "        chil = [box_converter(i) for i in box.children]\n",
    "        footer = '\\n</div>'\n",
    "        toReturn = ''\n",
    "        for i in chil:\n",
    "            toReturn+=i+'\\n\\t'\n",
    "        return header + toReturn+footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div/>\n",
      "\t<div/>\n",
      "\t<checkbox/>\n",
      "\t<div/>\n",
      "\t<div/>\n",
      "\t<div/>\n",
      "\t\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "print(box_converter(boxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"testBoxes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
